{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5e07f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home1/giorgian/projects/trigger-detection-pipeline/sPHENIX/trigger-detection/BGN-ST\n",
      "/home1/giorgian/projects/trigger-detection-pipeline/sPHENIX/trigger-detection/BGN-ST\n"
     ]
    }
   ],
   "source": [
    "%cd /home1/giorgian/projects/trigger-detection-pipeline/sPHENIX/trigger-detection/BGN-ST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac12ae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from dataloaders import get_data_loaders\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.log import load_checkpoint\n",
    "from collections import defaultdict\n",
    "from itertools import islice\n",
    "from tqdm.notebook import tqdm\n",
    "from models.Bipartite_Attention_gLRI2d import Bipartite_Attention as Model\n",
    "import numpy as np\n",
    "import matplotlib.colors as colors\n",
    "from sklearn.cluster import KMeans, OPTICS\n",
    "from scipy.stats import iqr\n",
    "from numpy.linalg import inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f3d0ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Î±=0.3\n",
    "config_file_path = 'train_results/biatt-glri/experiment_2023-04-19_21:29:02/config.pkl'\n",
    "with open(config_file_path, 'rb') as f:\n",
    "    config = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aa07472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.786766924722412e-05"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['lri']['sigma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a21d63f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0013863505131427945"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['lri']['beta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4806d13a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aggregator_activation': 'softmax',\n",
       " 'bn': True,\n",
       " 'hidden_activation': 'PReLU',\n",
       " 'ln': True,\n",
       " 'num_classes': 2,\n",
       " 'num_features': 30,\n",
       " 'recalculate_hits_mean': True,\n",
       " 'self_split': False,\n",
       " 'layers_spec': [[64, 8], [64, 8], [64, 8], [64, 8]]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb2f8101",
   "metadata": {},
   "outputs": [],
   "source": [
    "dconfig = config['data']\n",
    "dconfig['use_trigger'] = True\n",
    "dconfig['use_nontrigger'] = False\n",
    "dconfig['use_center'] = False\n",
    "train_data, val_data, test_data = get_data_loaders(**dconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a46c9954",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bipartite_Attention(\n",
       "  (interpreter): Bipartite_Attention(\n",
       "    (_layers): ModuleList(\n",
       "      (0): Bipartite_Layers(\n",
       "        (enc): ModuleList(\n",
       "          (0): Masked_SAB(\n",
       "            (mab): Masked_MAB(\n",
       "              (fc_q): Linear(in_features=30, out_features=64, bias=True)\n",
       "              (fc_k): Linear(in_features=30, out_features=64, bias=True)\n",
       "              (fc_v): Linear(in_features=30, out_features=64, bias=True)\n",
       "              (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (ln0): Masked_LayerNorm(\n",
       "                (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (ln1): Masked_LayerNorm(\n",
       "                (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Masked_SAB(\n",
       "            (mab): Masked_MAB(\n",
       "              (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (ln0): Masked_LayerNorm(\n",
       "                (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (ln1): Masked_LayerNorm(\n",
       "                (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (transform_in): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (aggregator_score): Linear(in_features=64, out_features=8, bias=True)\n",
       "        (transform_out): Sequential(\n",
       "          (0): Linear(in_features=1118, out_features=64, bias=True)\n",
       "          (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): PReLU(num_parameters=1)\n",
       "        )\n",
       "      )\n",
       "      (1): Bipartite_Layers(\n",
       "        (enc): ModuleList(\n",
       "          (0): Masked_SAB(\n",
       "            (mab): Masked_MAB(\n",
       "              (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (ln0): Masked_LayerNorm(\n",
       "                (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (ln1): Masked_LayerNorm(\n",
       "                (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Masked_SAB(\n",
       "            (mab): Masked_MAB(\n",
       "              (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (ln0): Masked_LayerNorm(\n",
       "                (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (ln1): Masked_LayerNorm(\n",
       "                (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (transform_in): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (aggregator_score): Linear(in_features=64, out_features=8, bias=True)\n",
       "        (transform_out): Sequential(\n",
       "          (0): Linear(in_features=1152, out_features=64, bias=True)\n",
       "          (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): PReLU(num_parameters=1)\n",
       "        )\n",
       "      )\n",
       "      (2): Bipartite_Layers(\n",
       "        (enc): ModuleList(\n",
       "          (0): Masked_SAB(\n",
       "            (mab): Masked_MAB(\n",
       "              (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (ln0): Masked_LayerNorm(\n",
       "                (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (ln1): Masked_LayerNorm(\n",
       "                (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Masked_SAB(\n",
       "            (mab): Masked_MAB(\n",
       "              (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (ln0): Masked_LayerNorm(\n",
       "                (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (ln1): Masked_LayerNorm(\n",
       "                (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (transform_in): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (aggregator_score): Linear(in_features=64, out_features=8, bias=True)\n",
       "        (transform_out): Sequential(\n",
       "          (0): Linear(in_features=1152, out_features=64, bias=True)\n",
       "          (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): PReLU(num_parameters=1)\n",
       "        )\n",
       "      )\n",
       "      (3): Bipartite_Layers(\n",
       "        (enc): ModuleList(\n",
       "          (0): Masked_SAB(\n",
       "            (mab): Masked_MAB(\n",
       "              (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (ln0): Masked_LayerNorm(\n",
       "                (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (ln1): Masked_LayerNorm(\n",
       "                (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Masked_SAB(\n",
       "            (mab): Masked_MAB(\n",
       "              (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (ln0): Masked_LayerNorm(\n",
       "                (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (ln1): Masked_LayerNorm(\n",
       "                (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (transform_in): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (aggregator_score): Linear(in_features=64, out_features=8, bias=True)\n",
       "        (transform_out): Sequential(\n",
       "          (0): Linear(in_features=1152, out_features=64, bias=True)\n",
       "          (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): PReLU(num_parameters=1)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (convert): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (_pred_layers): ModuleList(\n",
       "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (1): Masked_LayerNorm(\n",
       "        (ln): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): PReLU(num_parameters=1)\n",
       "      (3): Linear(in_features=128, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Bipartite_Attention(\n",
       "    (_layers): ModuleList(\n",
       "      (0): Bipartite_Layers(\n",
       "        (enc): ModuleList(\n",
       "          (0): Masked_SAB(\n",
       "            (mab): Masked_MAB(\n",
       "              (fc_q): Linear(in_features=30, out_features=64, bias=True)\n",
       "              (fc_k): Linear(in_features=30, out_features=64, bias=True)\n",
       "              (fc_v): Linear(in_features=30, out_features=64, bias=True)\n",
       "              (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (ln0): Masked_LayerNorm(\n",
       "                (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (ln1): Masked_LayerNorm(\n",
       "                (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Masked_SAB(\n",
       "            (mab): Masked_MAB(\n",
       "              (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (ln0): Masked_LayerNorm(\n",
       "                (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (ln1): Masked_LayerNorm(\n",
       "                (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (transform_in): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (aggregator_score): Linear(in_features=64, out_features=8, bias=True)\n",
       "        (transform_out): Sequential(\n",
       "          (0): Linear(in_features=1118, out_features=64, bias=True)\n",
       "          (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): PReLU(num_parameters=1)\n",
       "        )\n",
       "      )\n",
       "      (1): Bipartite_Layers(\n",
       "        (enc): ModuleList(\n",
       "          (0): Masked_SAB(\n",
       "            (mab): Masked_MAB(\n",
       "              (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (ln0): Masked_LayerNorm(\n",
       "                (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (ln1): Masked_LayerNorm(\n",
       "                (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Masked_SAB(\n",
       "            (mab): Masked_MAB(\n",
       "              (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (ln0): Masked_LayerNorm(\n",
       "                (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (ln1): Masked_LayerNorm(\n",
       "                (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (transform_in): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (aggregator_score): Linear(in_features=64, out_features=8, bias=True)\n",
       "        (transform_out): Sequential(\n",
       "          (0): Linear(in_features=1152, out_features=64, bias=True)\n",
       "          (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): PReLU(num_parameters=1)\n",
       "        )\n",
       "      )\n",
       "      (2): Bipartite_Layers(\n",
       "        (enc): ModuleList(\n",
       "          (0): Masked_SAB(\n",
       "            (mab): Masked_MAB(\n",
       "              (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (ln0): Masked_LayerNorm(\n",
       "                (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (ln1): Masked_LayerNorm(\n",
       "                (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Masked_SAB(\n",
       "            (mab): Masked_MAB(\n",
       "              (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (ln0): Masked_LayerNorm(\n",
       "                (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (ln1): Masked_LayerNorm(\n",
       "                (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (transform_in): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (aggregator_score): Linear(in_features=64, out_features=8, bias=True)\n",
       "        (transform_out): Sequential(\n",
       "          (0): Linear(in_features=1152, out_features=64, bias=True)\n",
       "          (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): PReLU(num_parameters=1)\n",
       "        )\n",
       "      )\n",
       "      (3): Bipartite_Layers(\n",
       "        (enc): ModuleList(\n",
       "          (0): Masked_SAB(\n",
       "            (mab): Masked_MAB(\n",
       "              (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (ln0): Masked_LayerNorm(\n",
       "                (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (ln1): Masked_LayerNorm(\n",
       "                (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Masked_SAB(\n",
       "            (mab): Masked_MAB(\n",
       "              (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (ln0): Masked_LayerNorm(\n",
       "                (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (ln1): Masked_LayerNorm(\n",
       "                (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (transform_in): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (aggregator_score): Linear(in_features=64, out_features=8, bias=True)\n",
       "        (transform_out): Sequential(\n",
       "          (0): Linear(in_features=1152, out_features=64, bias=True)\n",
       "          (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): PReLU(num_parameters=1)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (score): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "    (_pred_layers): ModuleList(\n",
       "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (1): PReLU(num_parameters=1)\n",
       "      (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Linear(in_features=128, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (noiser): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): PReLU(num_parameters=1)\n",
       "    (3): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=64, out_features=30, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = 'cuda:1'\n",
    "checkpoint_file = 'train_results/biatt-glri/experiment_2023-04-19_21:29:02/checkpoints/model_checkpoint_010.pth.tar'\n",
    "mconfig = config['model']\n",
    "model = Model(**mconfig)\n",
    "model = load_checkpoint(checkpoint_file, model)\n",
    "model = model.to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b582f9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_approximate_radii(track_vector):\n",
    "    tracks_info = track_vector[:, :15]\n",
    "    good_hits = np.any(tracks_info.reshape(tracks_info.shape[0], 5, 3) != 0, axis=-1)\n",
    "    n_hits = np.sum(good_hits, axis=-1)\n",
    "    x_indices = [3*j for j in range(5)]\n",
    "    y_indices = [3*j+1 for j in range(5)]\n",
    "    r = np.zeros((tracks_info.shape[0], 1))\n",
    "    centers = np.zeros((tracks_info.shape[0], 2))\n",
    "    for n_hit in range(3, 5 + 1):\n",
    "        complete_tracks = tracks_info[n_hits == n_hit]\n",
    "        hit_indices = good_hits[n_hits == n_hit]\n",
    "        if complete_tracks.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        A = np.ones((complete_tracks.shape[0], n_hit, 3))\n",
    "        x_values = complete_tracks[:, x_indices]\n",
    "        x_values = x_values[hit_indices].reshape(complete_tracks.shape[0], n_hit)\n",
    "\n",
    "        y_values = complete_tracks[:, y_indices]\n",
    "        y_values = y_values[hit_indices].reshape(complete_tracks.shape[0], n_hit)\n",
    "        A[:, :, 0] = x_values\n",
    "        A[:, :, 1] = y_values\n",
    "\n",
    "        y = - x_values**2 - y_values**2\n",
    "        y = y.reshape((y.shape[0], y.shape[1], 1))\n",
    "        AT = np.transpose(A, axes=(0, 2, 1))\n",
    "        c = matmul_3D(matmul_3D(inv(matmul_3D(AT, A)), AT), y)\n",
    "        r[n_hits == n_hit] == 1\n",
    "        r[n_hits == n_hit] = np.sqrt(c[:, 0]**2 + c[:, 1]**2 - 4*c[:, 2])/200\n",
    "        centers[n_hits == n_hit] = np.concatenate([-c[:, 0]/2, -c[:, 1]/2], axis=-1)\n",
    "    #test = get_approximate_radius(tracks_info, n_hits == 5)\n",
    "    #assert np.allclose(test, r[n_hits == 5])\n",
    "\n",
    "    return r, centers\n",
    "\n",
    "def matmul_3D(A, B):\n",
    "    return np.einsum('lij,ljk->lik', A, B)\n",
    "\n",
    "def decode(n):\n",
    "    if n == 0b00:\n",
    "        return 'tt'\n",
    "    elif n == 0b01:\n",
    "        return 'pt'\n",
    "    elif n == 0b10:\n",
    "        return 'tp'\n",
    "    else:\n",
    "        return 'tt'\n",
    "    vectors = ['t', 'p']\n",
    "    if n == 0:\n",
    "        return '0'\n",
    "    nums = []\n",
    "    while n:\n",
    "        n, r = divmod(n, 2)\n",
    "        nums.append(vectors[r])\n",
    "    return ''.join(nums)\n",
    "\n",
    "def calculate_n_bins(values):\n",
    "    h = 2*iqr(values)/(len(values)**(1/3))\n",
    "    return int(np.round((np.max(values)-np.min(values))/h))\n",
    "\n",
    "\n",
    "def zipdict(d):\n",
    "    keys = tuple(d.keys())\n",
    "    for v in zip(*[d[key] for key in keys]):\n",
    "        yield dict(zip(keys, v))\n",
    "    \n",
    "    \n",
    "def dict_freeze(d):\n",
    "    if isinstance(d, defaultdict):\n",
    "        d = {k: dict_freeze(v) for k, v in d.items()}\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c79326f",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06b5880b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a61506b4a08482aae829951fc41ac63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3469610/3005717371.py:21: RuntimeWarning: invalid value encountered in divide\n",
      "  events['e_p'].append(e_p[..., :2]/np.expand_dims(np.linalg.norm(e_p[..., :2], axis=-1), -1))\n",
      "/tmp/ipykernel_3469610/3005717371.py:24: RuntimeWarning: invalid value encountered in divide\n",
      "  events['e_t'].append(e_t/np.expand_dims(np.linalg.norm(e_t, axis=-1), -1))\n"
     ]
    }
   ],
   "source": [
    "N_BATCHES = 100\n",
    "for batch in tqdm(islice(val_data, 0, N_BATCHES), total=N_BATCHES):\n",
    "    mask = torch.zeros(batch.track_vector.shape[:-1])\n",
    "    for i, n in enumerate(batch.n_tracks):\n",
    "        mask[i, :n] = 1\n",
    "        \n",
    "    mask = mask.to(DEVICE)\n",
    "    track_vector = batch.track_vector.to(DEVICE)\n",
    "    is_trigger_track = batch.is_trigger_track.to(DEVICE, torch.bool)\n",
    "    trigger = (batch.trigger.to(DEVICE) == 1).unsqueeze(-1)\n",
    "    \n",
    "    _, pred_sigmas, valid_hits = model(track_vector, mask)\n",
    "    for i, (track, momentum, origin_vertex, n_tracks) in enumerate(zip(batch.track_vector, batch.momentums, batch.origin_vertices, batch.n_tracks)):\n",
    "        r, c = get_approximate_radii(track[:n_tracks].detach().cpu().numpy())\n",
    "        events['hits'].append(track[:n_tracks, :15].reshape(n_tracks, 5, 3).detach().cpu().numpy())\n",
    "        x = events['hits'][-1][..., 0]\n",
    "        y = events['hits'][-1][..., 1]\n",
    "        c_x = c[..., 0]\n",
    "        c_y = c[..., 1]\n",
    "        e_p = np.stack([(x - np.expand_dims(c_x, -1)), (y - np.expand_dims(c_y, -1)), np.zeros(y.shape)], axis=-1)\n",
    "        events['e_p'].append(e_p[..., :2]/np.expand_dims(np.linalg.norm(e_p[..., :2], axis=-1), -1))\n",
    "        z = np.array([0, 0, 1]).reshape(1, 1, -1)\n",
    "        e_t = np.cross(e_p, z)[..., :2]\n",
    "        events['e_t'].append(e_t/np.expand_dims(np.linalg.norm(e_t, axis=-1), -1))\n",
    "        events['trigger_mask'].append(is_trigger_track[i][:n_tracks].unsqueeze(-1).repeat(1, 5).detach().cpu().numpy())\n",
    "        events['good_hits_mask'].append(valid_hits[i][:n_tracks].detach().cpu().numpy())\n",
    "        events['sigmas'].append(pred_sigmas[i][:n_tracks].detach().cpu().numpy())\n",
    "events = dict_freeze(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0d0e5f",
   "metadata": {},
   "source": [
    "# Symmetricity Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fd7728",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "for event in zipdict(events):\n",
    "    event['n_hits'] = np.expand_dims(np.sum(event['good_hits_mask'], axis=-1), -1).repeat(5, -1).reshape(-1)\n",
    "    event['good_hits_mask'] = event['good_hits_mask'].reshape(-1)\n",
    "    event['trigger_mask'] = event['trigger_mask'].reshape(-1)\n",
    "    masks = {'all': event['good_hits_mask'], \n",
    "             'trigger': event['good_hits_mask'] * event['trigger_mask'], \n",
    "             'nontrigger': event['good_hits_mask'] * ~event['trigger_mask']\n",
    "            }\n",
    "\n",
    "    basis = np.stack([event['e_t'], event['e_p']], axis=-1) # Stack them in the column.\n",
    "    basis = basis.reshape(-1, 2, 2)\n",
    "    for name, mask in masks.items():\n",
    "        sigmas = event['sigmas'].reshape(-1, 2, 2)[mask]\n",
    "        eigenvalues, eigenvectors = np.linalg.eig(sigmas)\n",
    "        order = np.argsort(eigenvalues, axis=-1)\n",
    "        eigenvectors = np.take_along_axis(eigenvectors, np.expand_dims(order, 1), -1)\n",
    "        eigenvalues = np.sort(eigenvalues, axis=-1)\n",
    "        coefficients = np.einsum('hfb,hfe->heb', basis[mask], eigenvectors)\n",
    "        hits[name]['coefficients'].extend(coefficients)\n",
    "        hits[name]['eigenvectors'].extend(eigenvectors)\n",
    "        hits[name]['eigenvalues'].extend(eigenvalues)\n",
    "        hits[name]['symmetricity'].extend(np.prod(eigenvalues, axis=-1)/np.max(eigenvalues, axis=-1)**2)\n",
    "        hits[name]['n_hits'].extend(event['n_hits'][mask])\n",
    "        hits[name]['e_t'].extend(event['e_t'].reshape(-1, 2)[mask])\n",
    "        hits[name]['e_p'].extend(event['e_p'].reshape(-1, 2)[mask])\n",
    "        \n",
    "for hit_type in hits.keys():\n",
    "    for attribute in hits[hit_type].keys():\n",
    "        hits[hit_type][attribute] = np.stack(hits[hit_type][attribute], axis=0)\n",
    "hits = dict_freeze(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623eb92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(hits), 1)\n",
    "peaks_dict = {}\n",
    "for axis, (key, attributes) in zip(axes, hits.items()):\n",
    "    n_bins = calculate_n_bins(attributes['symmetricity'])\n",
    "    counts, bins, _ = axis.hist(attributes['symmetricity'], bins=n_bins)\n",
    "    axis.set_title(f'{key.capitalize()} Symmetricities')\n",
    "    axis.set_xlabel('Symmetricities')\n",
    "    axis.set_ylabel('Count')\n",
    "    axis.set_xlim(0, 1)\n",
    "    peaks_dict[key] = bins[np.argsort(counts)[-2:]]\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221d4121",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clusters_dict = {}\n",
    "for key, attributes in hits.items():\n",
    "    symmetricity = attributes['symmetricity']\n",
    "    peaks = peaks_dict[key]\n",
    "    clusters_dict[key] = KMeans(n_clusters=len(peaks), init=np.sort(peaks).reshape(-1, 1), n_init=1).fit(symmetricity.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13757251",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_ranges_dict = defaultdict(lambda: {})\n",
    "colors = ['#a6cee3', '#1f78b4', '#b2df8a', '#33a02c']\n",
    "fig, axes = plt.subplots(len(clusters_dict), 1)\n",
    "for axis, (key, classifier) in zip(axes, clusters_dict.items()):\n",
    "    symmetricities = hits[key]['symmetricity']\n",
    "    n_bins = calculate_n_bins(symmetricities)\n",
    "    _, bins, rectangles = axis.hist(symmetricities, bins=n_bins)\n",
    "    bin_centers = np.mean(np.stack([bins[:-1], bins[1:]], axis=-1), axis=-1)\n",
    "    bin_classes = classifier.predict(bin_centers.reshape(-1, 1).astype(np.float32))\n",
    "    edge_classes = classifier.predict(bins.reshape(-1, 1).astype(np.float32))\n",
    "    cluster_order = np.argsort(classifier.cluster_centers_.squeeze(1))\n",
    "    for i in range(len(classifier.cluster_centers_)):\n",
    "        mode_ranges_dict[key][i] = (np.min(bins[edge_classes == cluster_order[i]]), np.max(bins[edge_classes == cluster_order[i]]))\n",
    "        \n",
    "    for rectangle, bin_class in zip(rectangles, bin_classes):\n",
    "        rectangle.set(color=colors[bin_class])\n",
    "    axis.set_title(f'{key.capitalize()} Symmetricities')\n",
    "    axis.set_xlabel('Symmetricity')\n",
    "    axis.set_ylabel('Count')\n",
    "    axis.set_xlim(0, 1)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab65c12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(mode_ranges_dict), 2, figsize=(10, 10))\n",
    "\n",
    "for axes_row, (key, mode_ranges) in zip(axes, mode_ranges_dict.items()):\n",
    "    for i, (axis, (b, e)) in enumerate(zip(axes_row, mode_ranges.values())):\n",
    "        attributes = hits[key]\n",
    "        symmetricities = attributes['symmetricity']\n",
    "        mask = (symmetricities >= b) & (symmetricities < e)\n",
    "        v = attributes['eigenvalues']\n",
    "        l1, l2 = v[:, -1][mask], v[:, -2][mask]\n",
    "        n_x_bins = calculate_n_bins(l1/l2)\n",
    "        res = axis.hist(l1/l2, bins=n_x_bins)\n",
    "        axis.set_title(f'{key.capitalize()} Hits Mode {i+1}')\n",
    "        axis.set_xlabel('$\\lambda_1/\\lambda_2$')\n",
    "        axis.set_ylabel('Count')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fe558b",
   "metadata": {},
   "source": [
    "## Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f325ca9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(mode_ranges_dict), 2, figsize=(15, 15))\n",
    "\n",
    "for axes_row, (key, mode_ranges) in zip(axes, mode_ranges_dict.items()):\n",
    "    for i, (axis, (b, e)) in enumerate(zip(axes_row, mode_ranges.values())):\n",
    "        attributes = hits[key]\n",
    "        symmetricities = attributes['symmetricity']\n",
    "        mask = (symmetricities >= b) & (symmetricities < e)\n",
    "        coefficients = attributes['coefficients'][mask]\n",
    "        highest_base = np.argmax(np.abs(coefficients), axis=-1)\n",
    "        dist = np.sum(highest_base * np.array([2**1, 2**0]), axis=-1)\n",
    "        print(f'{highest_base[0]=} {dist[0]=} {decode(dist[0])=}')\n",
    "        #print(f'{highest_base=} {dist=}')\n",
    "        #break\n",
    "\n",
    "        keys = dict(zip(np.unique(np.sort(dist)), [decode(i) for i in np.unique(np.sort(dist))]))\n",
    "        x = [f'${keys[k]}$' for k in sorted(keys.keys())]\n",
    "        heights = [np.sum(dist == k) for k in sorted(keys.keys())]\n",
    "        axis.bar(x, heights)\n",
    "        #axis.set_yscale('log')\n",
    "        axis.set_title(f'Preferred Direction for {key.capitalize()} Hits Mode {i+1}')\n",
    "        axis.set_xlabel('Preferred Direction')\n",
    "        axis.set_ylabel('Count')\n",
    "                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1a4fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(mode_ranges_dict), 2, figsize=(15, 15))\n",
    "\n",
    "for axes_row, (key, mode_ranges) in zip(axes, mode_ranges_dict.items()):\n",
    "    for i, (axis, (b, e)) in enumerate(zip(axes_row, mode_ranges.values())):\n",
    "        attributes = hits[key]\n",
    "        symmetricities = attributes['symmetricity']\n",
    "        mask = (symmetricities >= b) & (symmetricities < e)\n",
    "        coefficients = attributes['coefficients'][mask]\n",
    "        highest_base = np.max(np.abs(coefficients), axis=-1)\n",
    "        axis.hist(highest_base)\n",
    "        #axis.set_yscale('log')\n",
    "        axis.set_title(f'Preferred Direction for {key.capitalize()} Hits Mode {i+1}')\n",
    "        axis.set_xlabel('Preferred Direction')\n",
    "        axis.set_ylabel('Count')\n",
    "                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7074c959",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
