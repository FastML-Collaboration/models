{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a14a8582-d53d-4deb-b4b4-82ca99a375bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd /home1/giorgian/projects/trigger-detection-pipeline/sPHENIX/tracking-GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd3c1658",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dataclasses import replace\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import os.path\n",
    "import sys\n",
    "import logging\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from numpy.linalg import inv\n",
    "import sklearn.metrics as metrics\n",
    "from datasets import get_data_loaders\n",
    "from tqdm.notebook import tqdm\n",
    "import glob\n",
    "from datasets.hit_graph_trigger_pileup import load_graph\n",
    "from torch_geometric.data import Data\n",
    "import dataclasses\n",
    "from disjoint_set import DisjointSet\n",
    "from typing import Union\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f738b3f4-78a5-4735-b722-2848d5b3421a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class EventInfo:\n",
    "    n_pixels: Union[np.ndarray, torch.Tensor]\n",
    "    energy: Union[np.ndarray, torch.Tensor]\n",
    "    momentum: Union[np.ndarray, torch.Tensor]\n",
    "    interaction_point: Union[np.ndarray, torch.Tensor]\n",
    "    trigger: Union[bool, torch.Tensor]\n",
    "    has_trigger_pair: Union[bool, torch.Tensor]\n",
    "    track_origin: Union[np.ndarray, torch.Tensor]\n",
    "    trigger_node: Union[np.ndarray, torch.Tensor]\n",
    "    particle_id: Union[np.ndarray, torch.Tensor]\n",
    "    particle_type: Union[np.ndarray, torch.Tensor]\n",
    "    parent_particle_type: Union[np.ndarray, torch.Tensor]\n",
    "    track_hits: Union[np.ndarray, torch.Tensor]\n",
    "    track_n_hits: Union[np.ndarray, torch.Tensor]\n",
    "\n",
    "\n",
    "\n",
    "def get_tracks(edge_index):\n",
    "    # Get connected components\n",
    "    ds = DisjointSet()\n",
    "    for i in range(edge_index.shape[1]):\n",
    "        ds.union(edge_index[0, i], edge_index[1, i])\n",
    "\n",
    "    return tuple(list(x) for x in ds.itersets())\n",
    "\n",
    "def load_graph(filename, min_edge_probability, intt_required=False):\n",
    "    layers = [(0,), (1,), (2,), (3,4), (5,6)]\n",
    "    with np.load(filename, allow_pickle=True) as f:\n",
    "        model_edge_probability = f['model_edge_probability']\n",
    "        edge_index = f['edge_index'][:, model_edge_probability >= min_edge_probability]\n",
    "        tracks = get_tracks(edge_index)\n",
    "        if intt_required:\n",
    "            tracks = [track for track in tracks if np.any(f['layer_id'][track] >= 3)]\n",
    "\n",
    "        track_hits = np.zeros((len(tracks), 3*len(layers)))\n",
    "        n_pixels = np.zeros((len(tracks), len(layers)))\n",
    "        energy = np.zeros(len(tracks))\n",
    "        momentum = np.zeros((len(tracks), 3))\n",
    "        track_origin = np.zeros((len(tracks), 3))\n",
    "        trigger_node = np.zeros(len(tracks))\n",
    "        particle_id = np.zeros(len(tracks))\n",
    "        particle_type = np.zeros(len(tracks))\n",
    "        parent_particle_type = np.zeros(len(tracks))\n",
    "        track_n_hits = np.zeros((len(tracks), len(layers)))\n",
    "\n",
    "        for i, track in enumerate(tracks):\n",
    "            layer_id = f['layer_id'][track]\n",
    "            hit_n_pixels = f['n_pixels'][track]\n",
    "            hits = f['hit_cartesian'][track]\n",
    "\n",
    "            # Calculate per-layer information\n",
    "            for j, layer in enumerate(layers):\n",
    "                mask = np.isin(layer_id, layer)\n",
    "                weighted_hits = hit_n_pixels[mask, None] * hits[mask]\n",
    "                d = np.sum(hit_n_pixels[mask])\n",
    "\n",
    "                track_hits[i, 3*j:3*(j+1)] = np.sum(weighted_hits, axis=0)/(d + (d == 0))\n",
    "                n_pixels[i, j] = d\n",
    "                track_n_hits[i, j] = np.sum(mask)\n",
    "            \n",
    "            # Find the GT particle that this track is assigned to\n",
    "            pids = f['particle_id'][track]\n",
    "            particle_id[i] = mode(pids, axis=0, keepdims=False).mode\n",
    "            if np.isnan(particle_id[i]):\n",
    "                index = track[np.where(np.isnan(pids))[0][0]]\n",
    "            else:\n",
    "                index = track[np.where(pids == particle_id[i])[0][0]]\n",
    "\n",
    "            energy[i] = f['energy'][index]\n",
    "            momentum[i] = f['momentum'][index]\n",
    "            track_origin[i] = f['track_origin'][index]\n",
    "            trigger_node[i] = f['trigger_node'][index]\n",
    "            particle_type[i] = f['particle_type'][index]\n",
    "            parent_particle_type[i] = f['parent_particle_type'][index]\n",
    "\n",
    "        return EventInfo(\n",
    "                n_pixels=n_pixels,\n",
    "                energy=energy,\n",
    "                momentum=momentum,\n",
    "                interaction_point=f['interaction_point'],\n",
    "                trigger=f['trigger'],\n",
    "                has_trigger_pair=f['has_trigger_pair'],\n",
    "                track_origin=track_origin,\n",
    "                trigger_node=trigger_node,\n",
    "                particle_id=particle_id,\n",
    "                particle_type=particle_type,\n",
    "                parent_particle_type=parent_particle_type,\n",
    "                track_hits=track_hits,\n",
    "                track_n_hits=track_n_hits\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ae0de67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69228eea423d4fd6a5ea468d3cf1c7c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1039700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/largehome/giorgian/projects/trigger-detection-pipeline/sPHENIX/tracking-GNN/models/garnet_ip.py:127: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1724789560443/work/torch/csrc/tensor/python_tensor.cpp:78.)\n",
      "  temp = torch.cuda.FloatTensor(x.shape[0]).fill_(1)\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trigger_files = glob.glob('/ssd2/giorgian/hits-data-august-2024/trigger/1/*.npz')\n",
    "nontrigger_files = glob.glob('/ssd/giorgian/hits-data-august-2024/trigger/1/*.npz')\n",
    "trigger_output_dir = '/home/giorgian/beautyllm-pileup/trigger/'\n",
    "nontrigger_output_dir = '/home/giorgian/beautyllm-pileup/nontrigger/'\n",
    "\n",
    "output_dirs = (trigger_output_dir, nontrigger_output_dir)\n",
    "\n",
    "for output_dir in output_dirs:\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "all_files = trigger_files + nontrigger_files\n",
    "cylindrical_features_scale=np.array([3, 1, 3])\n",
    "# Loop over each file\n",
    "for filename in tqdm(all_files):\n",
    "    # Load the graph data\n",
    "    event_info = load_graph(\n",
    "        filename,\n",
    "        0.5,\n",
    "        intt_required=True\n",
    "    )   \n",
    "    \n",
    "   \n",
    "    if 'event1' in filename:\n",
    "        output_file = os.path.join(trigger_output_dir, os.path.basename(filename))\n",
    "    else:\n",
    "        output_file = os.path.join(nontrigger_output_dir, os.path.basename(filename))\n",
    "    output_file = output_file.replace('.npz', '.txt')\n",
    "\n",
    "    with open(output_file, 'w') as fout:\n",
    "        print(f'Here is a particle collision event with {len(tracks)} tracks.', file=fout)\n",
    "        print(f'The collision vertex is {tuple(pred_ip.tolist())}.', file=fout)\n",
    "    \n",
    "        for i, ti in enumerate(np.random.permutation(tracks.shape[0])):\n",
    "            print(f'Track number {i+1} has a transverse momentum of {radii[ti]}, a parallel momentum of {p_z[ti]}, a center of {tuple(centers[ti].tolist())} and a trajectory of {tuple(tracks[ti].tolist())} as the particle flew through the detector.', file=fout)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503a8d6a-5c7c-4acb-af79-f3aa0daec915",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
