{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d6ad8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import replace\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import sys\n",
    "import logging\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from models.garnet_trigger import GNNGraphClassifier\n",
    "from numpy.linalg import inv\n",
    "import sklearn.metrics as metrics\n",
    "from datasets import get_data_loaders\n",
    "from tqdm.notebook import tqdm\n",
    "from datasets.hit_graph_trigger_pileup import load_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d31de6cf-976b-4c29-a413-6df4916b5137",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88d47842-a8dd-4e21-9c6a-61b4a6b1dce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home1/giorgian/projects/trigger-detection-pipeline/sPHENIX/trigger_results/agnn/agnn-lr8.19806576478371e-05-b12-d71-PReLU-gi1-ln-True-n1600000/experiment_2024-04-26_13:41:37/checkpoints/model_checkpoint_011.pth.tar\n",
      "Successfully reloaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_915285/7784767.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=torch.device('cpu'))\n"
     ]
    }
   ],
   "source": [
    "# create model and load checkpoint\n",
    "#model_result_folder = '/home1/giorgian/projects/trigger-detection-pipeline/sPHENIX/trigger_results/agnn/agnn-lr8.19806576478371e-05-b12-d71-PReLU-gi1-ln-True-n1600000/experiment_2024-04-26_13:41:37'\n",
    "#MLP Trigger Layerwise\n",
    "model_result_folder = '/home1/giorgian/projects/trigger-detection-pipeline/sPHENIX/trigger_results/agnn/agnn-lr8.19806576478371e-05-b12-d71-PReLU-gi1-ln-True-n1600000/experiment_2024-04-26_13:41:37'\n",
    "config_file = model_result_folder + '/config.pkl'\n",
    "config = pickle.load(open(config_file, 'rb'))\n",
    "data_config = config.get('data')\n",
    "dphi_max, dz_max = data_config['phi_slope_max'], data_config['z0_max']\n",
    "\n",
    "model_config = config.get('model', {})\n",
    "model_config.pop('loss_func')\n",
    "model_config.pop('name')\n",
    "model = GNNGraphClassifier(**model_config).to(DEVICE)\n",
    "\n",
    "def load_checkpoint(checkpoint_file, model, optimizer=None):\n",
    "    checkpoint = torch.load(checkpoint_file, map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    if optimizer != None:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        return model, optimizer\n",
    "    return model\n",
    "\n",
    "# load_checkpoint\n",
    "checkpoint_dir = os.path.join(model_result_folder, 'checkpoints')\n",
    "checkpoint_file = sorted([os.path.join(checkpoint_dir, f) for f in os.listdir(checkpoint_dir) if f.startswith('model_checkpoint')])\n",
    "checkpoint_file = checkpoint_file[-1]\n",
    "print(checkpoint_file)\n",
    "model = load_checkpoint(checkpoint_file, model)\n",
    "print('Successfully reloaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2eefaad-ab99-4f38-a121-bd8a90dce915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 12,\n",
       " 'construct_edges': False,\n",
       " 'input_dir': '/ssd3/giorgian/hits-data-march-2024/trigger/1/',\n",
       " 'input_dir2': '/ssd2/giorgian/hits-data-august-2022/nontrigger/0/',\n",
       " 'load_full_event': False,\n",
       " 'n_folders': 2,\n",
       " 'n_mix': 10,\n",
       " 'n_train': 800000,\n",
       " 'n_valid': 175000,\n",
       " 'n_workers': 16,\n",
       " 'name': 'hit_graph_trigger_pileup',\n",
       " 'phi_slope_max': 0.012193355583173944,\n",
       " 'real_weight': 1,\n",
       " 'z0_max': 14.220353082111805,\n",
       " 'use_intt': False}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_config['use_intt'] = False\n",
    "data_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d705a116-3b85-4d40-bb46-47fe763802d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader, valid_data_loader = get_data_loaders(distributed=False, rank=0, n_ranks=0, **data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87f8fd28-5c19-4f5e-8c84-ab78c5ad8fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "self = train_data_loader.dataset.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21522034-79dd-4c56-ab0a-a45c89ec926c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ti = iter(train_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c643725d-45c3-4cf9-a931-9a815ff47735",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8579ac9f-0c2d-4ae5-84e2-14cd82d7b3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives = self.get_negatives(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecf27a03-354c-4961-a536-63f271470cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = self.get_positives(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b688d12-eb7c-43cc-8fdd-347ec1358375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4831]), torch.Size([4831, 5]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positives.active_node.shape, positives.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1ffe8c9-b958-45d3-98e3-a815c8723cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4918]), torch.Size([4918, 5]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.active_node.shape, batch.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea7ee9bd-4884-4f12-afb3-d5d3816dfd06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4646]), torch.Size([4646, 5]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negatives.active_node.shape, negatives.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bba2c46b-5b15-4e0c-a3f6-7d24456af97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.x = batch.x.to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "199def36-87b6-4bc0-b088-d384f4e1cca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/giorgian/projects/trigger-detection-pipeline/sPHENIX/tracking-GNN/models/garnet_trigger.py:132: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1724789560443/work/torch/csrc/tensor/python_tensor.cpp:78.)\n",
      "  temp = torch.cuda.FloatTensor(x.shape[0]).fill_(1)\n"
     ]
    }
   ],
   "source": [
    "anchor = model.encode(batch.to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e008f7f-caf4-4266-bc5a-9e7d9210dbed",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype, but got Double and Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m positives \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(positives\u001b[38;5;241m.\u001b[39mto(DEVICE))\n",
      "File \u001b[0;32m~/projects/trigger-detection-pipeline/sPHENIX/tracking-GNN/models/garnet_trigger.py:131\u001b[0m, in \u001b[0;36mGNNGraphClassifier.encode\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;66;03m# Apply input network to get hidden representation\u001b[39;00m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;66;03m# print(self.input_network.state_dict())\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_network(inputs\u001b[38;5;241m.\u001b[39mx)\n\u001b[1;32m    132\u001b[0m     temp \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mFloatTensor(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mfill_(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    133\u001b[0m     n_hits \u001b[38;5;241m=\u001b[39m scatter_add(temp, inputs\u001b[38;5;241m.\u001b[39mbatch)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/jupyter/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/jupyter/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/jupyter/lib/python3.12/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/jupyter/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/jupyter/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/jupyter/lib/python3.12/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype, but got Double and Float"
     ]
    }
   ],
   "source": [
    "positives = model.encode(positives.to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a615be-e0ab-45d6-aa08-bd3719722ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives = model.encode(negatives.to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ab2db20-9227-4777-b3f4-1c675b609883",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'active_node'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m positives\u001b[38;5;241m.\u001b[39mactive_node\u001b[38;5;241m.\u001b[39mshape, positives\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'active_node'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae42c059-2d94-43cb-9056-4b28d12c4218",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.nn.TripletMarginLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79209c26-b618-44a6-bee0-d2a93a56e108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0001, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c(anchor, positives, negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84438949-2102-40c3-875f-449996018f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "603"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch.active_node[batch.active_node.to(bool)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4619e49b-f9fc-45a3-bf12-c795aef8e491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4771"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch.active_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad093952-6dc5-4a6c-a079-9e0cef4a9b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_index=0 batch_trigger_value=tensor(False)\n",
      "batch_index=1 batch_trigger_value=tensor(False)\n",
      "batch_index=2 batch_trigger_value=tensor(False)\n",
      "batch_index=3 batch_trigger_value=tensor(False)\n",
      "batch_index=4 batch_trigger_value=tensor(True)\n",
      "batch_index=5 batch_trigger_value=tensor(False)\n",
      "batch_index=6 batch_trigger_value=tensor(True)\n",
      "batch_index=7 batch_trigger_value=tensor(True)\n",
      "batch_index=8 batch_trigger_value=tensor(True)\n",
      "batch_index=9 batch_trigger_value=tensor(False)\n",
      "batch_index=10 batch_trigger_value=tensor(False)\n",
      "batch_index=11 batch_trigger_value=tensor(False)\n"
     ]
    }
   ],
   "source": [
    "active_nodes = batch.active_node.to(bool)\n",
    "inactive_nodes = ~active_nodes\n",
    "\n",
    "# Identify the batch indices and triggers for active nodes\n",
    "active_batch_indices = torch.unique(batch.batch[active_nodes], sorted=False)\n",
    "active_batch_triggers = batch.trigger[active_batch_indices]\n",
    "\n",
    "# Collect the node features and batch indices of the inactive nodes\n",
    "updated_node_features = batch.x[inactive_nodes]\n",
    "updated_batch_indices = batch.batch[inactive_nodes]\n",
    "num_inactive_nodes = updated_node_features.shape[0]\n",
    "\n",
    "new_node_features_list = []\n",
    "new_batch_indices_list = []\n",
    "\n",
    "# Determine filenames based on trigger type\n",
    "trigger_event_filenames = self.filenames_1 if self.f1_type else self.filenames_2\n",
    "non_trigger_event_filenames = self.filenames_2 if self.f1_type else self.filenames_1\n",
    "\n",
    "# Load new node features for each active batch index\n",
    "for batch_index_tensor, batch_trigger_value in zip(active_batch_indices, active_batch_triggers):\n",
    "    batch_index = batch_index_tensor.item()\n",
    "    print(f'{batch_index=} {batch_trigger_value=}')\n",
    "    if batch_trigger_value == 0:\n",
    "        filename = np.random.choice(non_trigger_event_filenames)\n",
    "    else:\n",
    "        filename = np.random.choice(trigger_event_filenames)\n",
    "    \n",
    "    new_node_features, edge_index, y, event_info = load_graph(\n",
    "        filename,\n",
    "        self.cylindrical_features_scale,\n",
    "        self.phi_slope_max,\n",
    "        self.z0_max,\n",
    "        use_intt=self.use_intt,\n",
    "        construct_edges=self.construct_edges,\n",
    "        drop_l1=self.drop_l1,\n",
    "        drop_l2=self.drop_l2,\n",
    "        drop_l3=self.drop_l3,\n",
    "        add_global_node=self.add_global_node\n",
    "    )\n",
    "    new_node_features_list.append(new_node_features)\n",
    "    new_batch_indices_list.append(np.ones(new_node_features.shape[0], dtype=int) * batch_index)\n",
    "    \n",
    "# Concatenate new node features and batch indices\n",
    "new_node_features_array = np.concatenate(new_node_features_list, axis=0)\n",
    "num_new_nodes = new_node_features_array.shape[0]\n",
    "\n",
    "updated_node_features = torch.cat(\n",
    "    [updated_node_features, torch.tensor(new_node_features_array).to(updated_node_features.device)],\n",
    "    dim=0\n",
    ")\n",
    "new_batch_indices_array = np.concatenate(new_batch_indices_list, axis=0)\n",
    "updated_batch_indices = torch.cat(\n",
    "    [updated_batch_indices, torch.tensor(new_batch_indices_array).to(updated_batch_indices.device)],\n",
    "    dim=0\n",
    ")\n",
    "\n",
    "# Update active_nodes: new nodes are active\n",
    "updated_active_nodes = torch.cat(\n",
    "    [torch.zeros(num_inactive_nodes, dtype=torch.bool),\n",
    "     torch.ones(num_new_nodes, dtype=torch.bool)],\n",
    "    dim=0\n",
    ").to(active_nodes.device)\n",
    "\n",
    "# Assign the updated tensors back to the batch object\n",
    "batch.x = updated_node_features\n",
    "batch.batch = updated_batch_indices\n",
    "batch.active_node = updated_active_nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b3a386d-5a88-4694-ac68-7c95fe93a08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_index=0 batch_trigger_value=tensor(True)\n",
      "batch_index=1 batch_trigger_value=tensor(True)\n",
      "batch_index=2 batch_trigger_value=tensor(True)\n",
      "batch_index=3 batch_trigger_value=tensor(True)\n",
      "batch_index=4 batch_trigger_value=tensor(False)\n",
      "batch_index=5 batch_trigger_value=tensor(True)\n",
      "batch_index=6 batch_trigger_value=tensor(False)\n",
      "batch_index=7 batch_trigger_value=tensor(False)\n",
      "batch_index=8 batch_trigger_value=tensor(False)\n",
      "batch_index=9 batch_trigger_value=tensor(True)\n",
      "batch_index=10 batch_trigger_value=tensor(True)\n",
      "batch_index=11 batch_trigger_value=tensor(True)\n"
     ]
    }
   ],
   "source": [
    "active_nodes = batch.active_node.to(bool)\n",
    "inactive_nodes = ~active_nodes\n",
    "\n",
    "# Identify the batch indices and triggers for active nodes\n",
    "active_batch_indices = torch.unique(batch.batch[active_nodes], sorted=False)\n",
    "active_batch_triggers = batch.trigger[active_batch_indices]\n",
    "\n",
    "# Collect the node features and batch indices of the inactive nodes\n",
    "updated_node_features = batch.x[inactive_nodes]\n",
    "updated_batch_indices = batch.batch[inactive_nodes]\n",
    "num_inactive_nodes = updated_node_features.shape[0]\n",
    "\n",
    "new_node_features_list = []\n",
    "new_batch_indices_list = []\n",
    "\n",
    "# Determine filenames based on trigger type\n",
    "trigger_event_filenames = self.filenames_1 if self.f1_type else self.filenames_2\n",
    "non_trigger_event_filenames = self.filenames_2 if self.f1_type else self.filenames_1\n",
    "\n",
    "# Load new node features for each active batch index\n",
    "for batch_index_tensor, batch_trigger_value in zip(active_batch_indices, active_batch_triggers):\n",
    "    batch_index = batch_index_tensor.item()\n",
    "    print(f'{batch_index=} {batch_trigger_value=}')\n",
    "    if batch_trigger_value == 0:\n",
    "        filename = np.random.choice(trigger_event_filenames)\n",
    "    else:\n",
    "        filename = np.random.choice(non_trigger_event_filenames)\n",
    "    \n",
    "    new_node_features, edge_index, y, event_info = load_graph(\n",
    "        filename,\n",
    "        self.cylindrical_features_scale,\n",
    "        self.phi_slope_max,\n",
    "        self.z0_max,\n",
    "        use_intt=self.use_intt,\n",
    "        construct_edges=self.construct_edges,\n",
    "        drop_l1=self.drop_l1,\n",
    "        drop_l2=self.drop_l2,\n",
    "        drop_l3=self.drop_l3,\n",
    "        add_global_node=self.add_global_node\n",
    "    )\n",
    "    new_node_features_list.append(new_node_features)\n",
    "    new_batch_indices_list.append(np.ones(new_node_features.shape[0], dtype=int) * batch_index)\n",
    "    \n",
    "# Concatenate new node features and batch indices\n",
    "new_node_features_array = np.concatenate(new_node_features_list, axis=0)\n",
    "num_new_nodes = new_node_features_array.shape[0]\n",
    "\n",
    "updated_node_features = torch.cat(\n",
    "    [updated_node_features, torch.tensor(new_node_features_array).to(updated_node_features.device)],\n",
    "    dim=0\n",
    ")\n",
    "new_batch_indices_array = np.concatenate(new_batch_indices_list, axis=0)\n",
    "updated_batch_indices = torch.cat(\n",
    "    [updated_batch_indices, torch.tensor(new_batch_indices_array).to(updated_batch_indices.device)],\n",
    "    dim=0\n",
    ")\n",
    "\n",
    "# Update active_nodes: new nodes are active\n",
    "updated_active_nodes = torch.cat(\n",
    "    [torch.zeros(num_inactive_nodes, dtype=torch.bool),\n",
    "     torch.ones(num_new_nodes, dtype=torch.bool)],\n",
    "    dim=0\n",
    ").to(active_nodes.device)\n",
    "\n",
    "# Assign the updated tensors back to the batch object\n",
    "batch.x = updated_node_features\n",
    "batch.batch = updated_batch_indices\n",
    "batch.active_node = updated_active_nodes\n",
    "batch.trigger = ~batch.trigger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3e04f23-547c-4d74-ab17-84062f03c277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_index=0 batch_trigger_value=tensor(False)\n",
    "batch_index=1 batch_trigger_value=tensor(False)\n",
    "batch_index=2 batch_trigger_value=tensor(False)\n",
    "batch_index=3 batch_trigger_value=tensor(False)\n",
    "batch_index=4 batch_trigger_value=tensor(True)\n",
    "batch_index=5 batch_trigger_value=tensor(False)\n",
    "batch_index=6 batch_trigger_value=tensor(True)\n",
    "batch_index=7 batch_trigger_value=tensor(True)\n",
    "batch_index=8 batch_trigger_value=tensor(True)\n",
    "batch_index=9 batch_trigger_value=tensor(False)\n",
    "batch_index=10 batch_trigger_value=tensor(False)\n",
    "batch_index=11 batch_trigger_value=tensor(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eab60490-a33a-4c2e-a1b4-bdde7b02fe17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4781])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.active_node.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "203d40eb-84d5-43f0-b8d6-c22ae48d9055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_index=0 batch_trigger_value=tensor(False)\n",
      "batch_index=1 batch_trigger_value=tensor(False)\n",
      "batch_index=2 batch_trigger_value=tensor(True)\n",
      "batch_index=3 batch_trigger_value=tensor(True)\n",
      "batch_index=4 batch_trigger_value=tensor(False)\n",
      "batch_index=5 batch_trigger_value=tensor(False)\n",
      "batch_index=6 batch_trigger_value=tensor(True)\n",
      "batch_index=7 batch_trigger_value=tensor(False)\n",
      "batch_index=8 batch_trigger_value=tensor(True)\n",
      "batch_index=9 batch_trigger_value=tensor(True)\n",
      "batch_index=10 batch_trigger_value=tensor(False)\n",
      "batch_index=11 batch_trigger_value=tensor(False)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "461f8a41-8be1-4479-99a1-7b73491a4128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  ...,  True,  True,  True])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_active_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54e9fbd7-e410-4372-bf90-b20eee67bd38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  0,  0,  ..., 11, 11, 11]),\n",
       " array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,\n",
       "         1.,  1.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "         2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "         2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "         2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "         2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "         2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "         2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "         2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "         2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "         2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "         2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "         2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "         2.,  2.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,\n",
       "         3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,\n",
       "         3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,\n",
       "         3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,\n",
       "         3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,\n",
       "         3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  4.,  4.,  4.,  4.,  4.,\n",
       "         4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,\n",
       "         4.,  4.,  4.,  4.,  4.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "         5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "         5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "         5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "         5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "         5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "         5.,  5.,  5.,  5.,  5.,  5.,  5.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "         6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "         6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "         6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "         6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "         6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "         6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "         6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "         6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "         6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "         6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "         6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "         6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  7.,  7.,  7.,\n",
       "         7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  8.,  8.,  8.,  8.,  8.,\n",
       "         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,\n",
       "         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,\n",
       "         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,\n",
       "         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,\n",
       "         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,\n",
       "         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,\n",
       "         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,\n",
       "         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,\n",
       "         8.,  8.,  8.,  8.,  8.,  8.,  8.,  9.,  9.,  9.,  9.,  9.,  9.,\n",
       "         9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,\n",
       "         9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,\n",
       "         9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,\n",
       "         9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,\n",
       "         9.,  9.,  9.,  9.,  9.,  9.,  9.,  9., 10., 10., 10., 10., 10.,\n",
       "        10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10.,\n",
       "        10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10.,\n",
       "        10., 10., 10., 10., 10., 10., 10., 10., 11., 11., 11., 11., 11.,\n",
       "        11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "        11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "        11.]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_batch, new_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5d7042-2cc6-4255-9043-3b4c7a2ed8e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4339465-9a39-4711-afcf-dd6f72eca91b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  0.,  0.,  ..., 11., 11., 11.], dtype=torch.float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db7ad7d9-9f9e-41c2-95fe-2f7d8160ed2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__annotations__',\n",
       " '__call__',\n",
       " '__cat_dim__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__inc__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_edge_attr_cls',\n",
       " '_edge_to_layout',\n",
       " '_edges_to_layout',\n",
       " '_get_edge_index',\n",
       " '_get_tensor',\n",
       " '_get_tensor_size',\n",
       " '_multi_get_tensor',\n",
       " '_put_edge_index',\n",
       " '_put_tensor',\n",
       " '_remove_edge_index',\n",
       " '_remove_tensor',\n",
       " '_store',\n",
       " '_tensor_attr_cls',\n",
       " '_to_type',\n",
       " 'apply',\n",
       " 'apply_',\n",
       " 'batch',\n",
       " 'batch_size',\n",
       " 'clone',\n",
       " 'coalesce',\n",
       " 'concat',\n",
       " 'contains_isolated_nodes',\n",
       " 'contains_self_loops',\n",
       " 'contiguous',\n",
       " 'coo',\n",
       " 'cpu',\n",
       " 'csc',\n",
       " 'csr',\n",
       " 'cuda',\n",
       " 'debug',\n",
       " 'detach',\n",
       " 'detach_',\n",
       " 'edge_attr',\n",
       " 'edge_attrs',\n",
       " 'edge_index',\n",
       " 'edge_stores',\n",
       " 'edge_subgraph',\n",
       " 'edge_weight',\n",
       " 'face',\n",
       " 'from_data_list',\n",
       " 'from_dict',\n",
       " 'generate_ids',\n",
       " 'get_all_edge_attrs',\n",
       " 'get_all_tensor_attrs',\n",
       " 'get_edge_index',\n",
       " 'get_example',\n",
       " 'get_tensor',\n",
       " 'get_tensor_size',\n",
       " 'has_isolated_nodes',\n",
       " 'has_self_loops',\n",
       " 'index_select',\n",
       " 'is_coalesced',\n",
       " 'is_cuda',\n",
       " 'is_directed',\n",
       " 'is_edge_attr',\n",
       " 'is_node_attr',\n",
       " 'is_sorted',\n",
       " 'is_sorted_by_time',\n",
       " 'is_undirected',\n",
       " 'keys',\n",
       " 'multi_get_tensor',\n",
       " 'node_attrs',\n",
       " 'node_offsets',\n",
       " 'node_stores',\n",
       " 'num_edge_features',\n",
       " 'num_edge_types',\n",
       " 'num_edges',\n",
       " 'num_faces',\n",
       " 'num_features',\n",
       " 'num_graphs',\n",
       " 'num_node_features',\n",
       " 'num_node_types',\n",
       " 'num_nodes',\n",
       " 'pin_memory',\n",
       " 'pos',\n",
       " 'put_edge_index',\n",
       " 'put_tensor',\n",
       " 'record_stream',\n",
       " 'remove_edge_index',\n",
       " 'remove_tensor',\n",
       " 'requires_grad_',\n",
       " 'share_memory_',\n",
       " 'size',\n",
       " 'snapshot',\n",
       " 'sort',\n",
       " 'sort_by_time',\n",
       " 'stores',\n",
       " 'stores_as',\n",
       " 'subgraph',\n",
       " 'time',\n",
       " 'to',\n",
       " 'to_data_list',\n",
       " 'to_dict',\n",
       " 'to_heterogeneous',\n",
       " 'to_namedtuple',\n",
       " 'up_to',\n",
       " 'update',\n",
       " 'update_tensor',\n",
       " 'validate',\n",
       " 'view',\n",
       " 'x',\n",
       " 'y']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2778db50-e678-4e2a-8024-f406a3210b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(553, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6a97b86-4a49-4adf-b3c9-22824f1966b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "        2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "        2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "        2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "        2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "        2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "        2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  3.,  3.,  3.,\n",
       "        3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,\n",
       "        3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,\n",
       "        3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,\n",
       "        3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,\n",
       "        3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  4.,\n",
       "        4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,\n",
       "        4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,\n",
       "        4.,  4.,  4.,  4.,  4.,  4.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "        6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "        6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "        6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "        6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "        6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  7.,  7.,  7.,  7.,  7.,\n",
       "        7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,\n",
       "        7.,  7.,  7.,  7.,  7.,  7.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,\n",
       "        8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,\n",
       "        8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,\n",
       "        8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,\n",
       "        8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,\n",
       "        8.,  8.,  8.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,\n",
       "        9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,\n",
       "        9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,\n",
       "        9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9., 10., 10., 10.,\n",
       "       10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10.,\n",
       "       10., 10., 10., 10., 10., 10., 11., 11., 11., 11., 11., 11., 11.,\n",
       "       11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "       11., 11., 11., 11., 11., 11., 11.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b541a84f-9a96-4dd8-855b-6cee980a0965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e7694f17-5ac0-4295-a429-4d74b86a16fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True, False,  True,  True,  True,  True, False,  True, False, False,\n",
       "         True, False])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c424a2-4a80-4a9d-97ab-72e6ea9b9c47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
